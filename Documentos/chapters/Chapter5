\chapter*{Optimizaci\'on}\label{Optimizacion}
\addcontentsline{toc}{chapter}{Optimizaci\'on} % si queremos que aparezca en el 
\markboth{}{} % encabezado

Luego del marco te\'orico en m\'etodos num\'ericos y computaci\'on de alto desempe\~no, presentamos los objetivos del trabajo.
Este trabajo tiene como objetivo la optimizaci\'on de diferentes funciones y estructuras de datos de una implementaci\'on del m\'etodo variacional de Rayleigh-Ritz, ya que esta implementaci\'on no escala lo suficiente, necesitando gran cantidad de memoria y tiempo de procesamiento a medida que el tama\~no de problema crece.
A lo largo de este cap\'itulo mostraremos las diferentes modificaciones algor\'itmicas y de estructuras de datos m\'as eficientes para lograr que el programa tome ordenes de tiempo y memoria menor logrando una mejor escalabilidad.

\section{Variables del Programa}
En estas secci\'on  hablaremos de la implementacion de las matrices del metodo en nuestro programa y de los parametros del tama\~no del problema. Cuales son, su dimensi\'on y que objeto sem\'antico representan.


\begin{enumerate}
    \item ${KORD}$ orden de los B-splines, el grado es ${kord-1}$
    \item ${L_{INT}}$ numero de intervalos en el que se divide al intervalo [$R_{MIN}$, $R_{MAX}$]
    \item $R_{MIN}$ y $R_{MAX}$ R m\'inimo y m\'aximo (respectivamente) donde empieza y termina el intervalo para la integraci\'on.
    \item ${INT}_G$ grado de integraci\'on por cuadratura
    \item Matriz $s$ de solapamiento del sistema por una particula, es una matriz de banda sim\'etrica de tama\~no KORD.
    \item Matriz $v_0$ de Potencial, es una matriz de banda sim\'etrica de tama\~no KORD.
    \item Matriz $ke$ de Energ\'ia cinetica, es una matriz de banda sim\'etrica de tama\~no KORD.
    \item $f$ Es la integral $\int_{-\infty}^{+\infty} {B_j(x_2) V_{int} B_l(x_2) dx_2}$, es una matriz de banda de tama\~no KORD.
    \item Matriz $Vef$ potencial de un pozo con dos particulas, tiene de dimensi\'on $R^4$ pero los elementos del conjunto ${Vef_{i, j, k, l} | \norm{i - j} \geq KORD o \norm{k - l} \geq KORD}$ son ceros.
    \item Hamiltoniano $hsim$, es una matriz dispersa y sim\'etrica.
    \item Matriz $ms$ solapamiento del sistema sim\'etrico de dos particulas.
    \item Matriz $mv$ potencial de un sistema sim\'etrico.
\end{enumerate}

\section{Funciones del Programa}
En estas secci\'on hablaremos de la implementacion de funciones para llevar a cabo el m\'etodo en nuestro programa.

\begin{enumerate}
    \item $calculo\_matrices$: Calcula las matrices s, ke y $v_0$
    \item $iteraccion$: Calcula la $V_{ef}$
    \item $sener$: simetrizaci\'on del sistema, esta funcion calcula $h_{sim}$, $ms$ y $mv$
    \item $bsplvb$: Calcula los bsplines no ceros en un punto.
    \item $gauleg$: Teniendo en cuenta los l\'imites inferior y superior de la integraci\'on x1 y x2, y dada n, esta rutina devuelve los arrays x [1..n] y w[1..n] de longitud n, que contienen las abscisas y los pesos del Gauss-Legendre n de punto en cuadratura.
    \item $bder$: derivada del spline en el punto.
\end{enumerate}

\section{Optimizaci\'on en Memoria}

La optimizaci\'on en cuanto a almacenamiento se da al intentar no almacenar ceros en la matrices (almacenar la m\'inima cantidad de ceros posibles sin desmerecer la eficiencia computacional de 
operaciones de matrices y vectores) y no almacenar datos que no requieren muchas operaciones para ser recalculados.

Para esto se utiliz\'o estructuras de matrices dispersas y se reemplazaron arreglos por funciones que devuelven el mismo valor dado un \'indice. Se utiliz\'o dos tipos de estructuras CDS ver \ref{CDS} y CCS \ref{CCS}.

\subsection{Matrices de Banda}
Las variables que estaban definidas en torno a la traza seg\'un la variable $KORD$ son $s, v_0, ke, f\ y\ g$ 
donde todas son sim\'etricas salvo $f$ y $g$ por lo tanto se utilizo una estructura de matriz de banda. 
Estas matrices son comprimdas de un orden de $\orderof{((L_{INT} + KORD)^2)}$ a $\orderof{((L_{INT}+
  KORD) KORD)}$. La variable $Vef$ es un tensor de banda por lo tanto se puede usar una estructura 
 analoga para almacenaje, por tanto es comprimida de un orden de $\orderof{((L_{INT} + KORD)^4)}$ a $\orderof{(( (L_{INT} + KORD) KORD)^2)}$

\subsection{Matrices de Almacenamiento de Columnas Comprimidas}
Para las matrices $hsim,\ ms,\ mv$ que no necesariamente est\'an definidas solo en torno a la traza (ver \ref{img:matstyle}) se utiliz\'o este tipo de almacenamiento, que tambi\'en es provechoso para el metodo de Arnoldi. Estas matrices est\'an comprimidas de un orden de $\orderof{(( L_{INT} + KORD)^4)}$ a $\orderof{(( L_{INT} + KORD)^2)}$

\begin{figure}[!htbp]
  \begin{center}
    \leavevmode

    \includegraphics[scale=0.3]{mat1.png}

    \caption{Distribuci\'on de elementos distintos de cero de las matrices $hsim$, $ms$. $mv$}
    \label{img:matstyle}
  \end{center}
\end{figure}

\begin{figure}[!htbp]
  \begin{center}
    \leavevmode

    \includegraphics[scale=0.3]{vef.png}

    \caption{Distribuci\'on de elementos distintos de cero de la matriz $Vef$}
    \label{img:matstyle}
  \end{center}
\end{figure}



\begin{figure}[!htbp]
  \begin{center}
    \leavevmode

    \includegraphics[scale=0.3]{ke,s,v0.png}

    \caption{Distribuci\'on de elementos distintos de cero de la matriz $Vef$}
    \label{img:matstyle}
  \end{center}
\end{figure}
    


\section{Optimizaci\'on en CPU}
La optimizaci\'on mas grande se debi\'o al reducir el espacio de c\'alculo de los ciclos (reduciendo las iteraciones de los ciclos), tomando solo los valores no cero de la matriz, ya que estos pueden saberse de antemanos. 
Y como el tama\~no de los no ceros es en orden menor al tama\~no de los ceros esto permite una gran mejora en tiempo computacional, reduciendo complejidad como explicaremos mas adelante.
Otras optimizaciones han sido por cacheo de resultados, factorizaci\'on de c\'odigo, c\'alculo de valores en vez de ser almacenados.

\subsection{Reducir el Espacio de C\'alculo}

Para reducir el espacio de c\'alculos se ha modificado los espacio de iteraci\'on en los ciclos del programa en los cuales se calculaba la matriz, de esa manera intentar calcular la menor cantidad de ceros. Para ello se estudi\'o la estructura de cada matriz, como ya explicamos en la secci\'on anterior de optimizaci\'on de memoria, algunas matrices son de banda y otras son dispersas sin esta propiedad (o no se cumple como uno desea).


\begin{enumerate}   
    \item Funci\'on Intersecci\'on: en esta funci\'on se paso de tener un orden de \orderof{$(L_{INT}\ INT_G\ (L_{INT}\ INT_G\ KORD\ KORD))$} a 
     \orderof{$(L_{INT}\ INT_G\ (L_{INT}\ INT_G\ KORD\ KORD\ +\ KORD\ KORD\ L_{INT}\ KORD))$}
    \item La funci\'on $t$: esta se calcula sin necesidad de memoria ya que es una funci\'on que tiene tres partes bien diferenciadas, donde la primera y la ultima son constantes y la segunda es lineal ver \ref{img:funciont}
    \item $sener$: en esta funci\'on se paso de tener un orden de \orderof(${(L_{INT} + KORD)^4}$) a \orderof(${(L\_INTERVALS + KORD)^2 KORD^2}$)
\end{enumerate}



\subsection{Factorizaci\'on de c\'odigo y cacheo de resultados}
Esta optimizaci\'on se raliza de intercambiar la anidaci\'on de ciclos para asi evitar recalcular una funci\'on con los mismos parametros.

Si bien anteriormente hablamos que reducir el uso de memoria por recalcular el valor de una funci\'on era conveniente, este no es el caso pues la funci\'on $bsplvb$ y $bder$ es costosa de calcular, por ende conviene hacer cacheo de la funci\'on en vez de recalcular.
Esta funci\'on se requiere calcular su valor repetidas veces en los procesos $interaccion$ y $calculo\ matrices$ y se abord\'o a la soluci\'on de su c\'alculo memorizando los resultados de la funci\'on, no fue posible factorizaci\'on.

En el c\'odigo \ref{cod:bef} y \ref{cod:after} podemos ver como el ciclo de $j$ se pasa unos niveles mas arriba en la anidaci\'on y como se calcula el vector $bders$ cacheando las funciones $bder$ para no recalcularlo en los cilos siguientes.

\begin{lstlisting}[language=C, caption={Antes de la factorizaci\'on en calculo matrices}, 
label=cod:bef]
for(unsigned int i = KORD-1; i<KORD+L_INT-1; ++i) {
    for(unsigned int m = i-KORD+1; m<=i; ++m) {
        for(unsigned int n = m; n<=i; ++n) {
            for(unsigned int j = 0; j<INT_G; ++j) {
                double bm = 0, bn = 0;

                rr = x[idx(k[i], j, INT_G)];
                bsplvb(KORD, rr, i, Sp, Sp_1);

                bm = bder(rr, t, KORD, nk, m, i, Sp, bm);
                bn = bder(rr, t, KORD, nk, n, i, Sp, bn);
                ke[idx(m-1, n-1, nb)] = ke[idx(m-1, n-1, nb)] + 0.5*w[idx(k[i], j, INT_G)]*bm*bn/me;
            }
        }
    }
}
\end{lstlisting}

\begin{lstlisting}[language=C, caption={Despu\'es de la factorizaci\'on calculo matrices}, 
label=cod:after]
for(unsigned int i = KORD-1; i<KORD+L_INT-1; ++i) {
    for(unsigned int j = 0; j<INT_G; ++j) {
        rr = x[idx(k[i], j, INT_G)];

        bsplvb(KORD, rr, i, Sp, Sp_1);

        for(unsigned int m = i-KORD+1; m<=i && m<nb ; ++m) {
            bders[m - (i-KORD+1)] = bder(m, i, Sp_1);
        }

        for(int k=0 ; k<KORD ; k++){
            for(unsigned int m = i-KORD+1, n = m + k; n<=i && n<nb ; ++m, ++n) {
                double bm = bders[m - (i-KORD+1)];
                double bn = bders[n - (i-KORD+1)];
                ke[idx(m-1, n-1, nb)] += 0.5*w[idx(k[i], j, INT_G)]*bm*bn/ME;
            }
        }
    }
}
\end{lstlisting}

\subsection{C\'alculo de Valores versus Almacenamiento}
Cuando el c\'alculo del valor es sencillo es mejor calcularlo nuevamente en vez de ir a buscarlo a memoria, puesto que eso produce m\'as fallos de cach\'e y el acceso a memoria es 100 veces m\'as lento \ref{memwall}

Tal es el caso de:
\begin{enumerate}
    \item Cuadratura Gausiana: La cuadratura se necesita en diferentes escalas, entonces se calcula s\'olo una vez (con escala uno) y luego se escala para los diferentes valores cada vez que se necesita tal escala y tambi\'en se ahorra memoria y tiempo de computo de todas las escalas.
    \item La funci\'on $t$: esta se calcula sin necesidad de memoria ya que es una funci\'on que tiene tres partes bien diferenciadas, donde la primera y la ultima son constantes y la segunda es lineal ver figura \ref{img:funciont}
\end{enumerate}


\begin{figure}[!htbp]
  \begin{center}
    \leavevmode

    \includegraphics[scale=0.15]{funcionT.png}

    \caption{Funcion T Restringida para observar su forma}
    \label{img:funciont}
  \end{center}
\end{figure}

\section{Optimizaci\'on en GPU}
Se implemento una version h\'ibrida (parte en GPU y parte en CPU) del m\'etodo $interaccion$, que es la funci\'on m\'as pesada.

La f\'ormula 
$$\Psi_{int} = \int_{0}^{R} \int_{0}^{R} B_i(r_1)B_m(r_2)U_{int}(\abs{r_1 - r_2})B_j(r_1)B_n(r_2)\ dr_1\ dr_2 $$
se puede paralelizar usando dos kernels, uno para calcular la integral interior y otra para calcular la integral externa.
El primer Kernel es llamado con $KORD^2$ n\'umero de hilos y $L_{INT}*INT_G$ cantidad de bloques. Y el segundo $KORD^{2}\ 2\ (KORD+1)$ cantidad de hilos y $L_{INT} + KORD - 3$ cantidad de bloques.
Lo que se realiz\'o en esta implementaci\'on fue paralelizar los ciclos $for$ anidados. El primer kernel implementa la parelizacion del siguiente c\'odigo \ref{frag:f} y el segundo de la sumatoria a $Vef$ \ref{frag:vef}

\begin{lstlisting}[language=C, caption={C\'alculo de la integral interna}, 
label=frag:f]
for(int j=0 ; j<INT_G ; j++){

  double rr1 = eval_xi(basek, j, x);
  
  double w1 = eval_wi(i, j, w);

  memset(f, 0, sizeof(f));

  for(int k=KORD ; k<KORD+L_INT ; k++){
    int basek2 = k - KORD;

    for(int l=0 ; l<INT_G ; l++){
      double rr2 = eval_xi(basek2, l, x);
      double w2 = eval_wi(basek2, l, w);
      double *Sp = Sps[basek2][l];

      for(int m=0 ; m<KORD ; m++){
        unsigned int im = k - KORD + m - 1;
        if(im<nb){
          for(int n=0; n < KORD ; n++){
            unsigned int in = k - KORD + n - 1;
            if(in<nb){
              if(rr2 <= rr1){
                f[im, in, nb] += Sp[m] * Sp[n] * w2/rr1;
              }else{
                f[im, in, nb] += Sp[m] * Sp[n] * w2/rr2;
              }
            }
          }
        }
      }
    }
  }
}
\end{lstlisting}

\begin{lstlisting}[language=C, caption={Suma sobre Vef}, 
label=frag:vef]
for(size_t m=0 ; m<KORD ; m++){
    size_t im = i - KORD + m - 1;
    if(im < nb){
      for(size_t mp=0 ; mp < KORD ; mp++){
        size_t imp = i - KORD + mp - 1;
        for(size_t n=0 ; n<nb ; n++){
          for(size_t np= n > KORD ? n - KORD : 0 ; np < n + KORD+1 && np < nb ; np++){
            double term = Sp[m]*Sp[mp]*w1*f[n, np]
                  / sqrt(s[n, n]*s[np, np]);
            Vef[im, n, imp, np] += term;
          }
        }
      }
    }
  }
}
\end{lstlisting}


Como al integrar se hace una suma con los coeficiente de la Cuadratura Gaussiana y estos son independiente se puede paralelizar, luego de integrar se van acomulando en la variable $Vef$. 
Entonces estos dos kernels CUDA son para calcular $f$ y otro para realizar la suma sobre $Vef$.

\subsection{Kernel de acomulaci\'on sobre $Vef$}

El Kernel que realiza la sumatoria se llama $L_{INT} + KORD$ blockes y un vector tridimensional de hilos de tama\~no ($KORD, KORD, 2\ KORD$).


\subsection{Integraci\'on}
El kernel que realiza la integraci\'on calcula de manera paralela la funciones $f$ y $g$ al ser acumulaciones son f\'acilmente paralelizables. 
Para esto se hizo un Kernel con la siguiente configuraci\'on de bloque e hilos por bloques: Un vector de dos dimensiones para los hilos por bloques de tama\~no ($KORD, KORD$) y un vector bidimensional de bloques de tama\~no ($L_{INT}, {INT}_{G}$)


%\setcounter{chapter}{6}
\setcounter{section}{0}
\chapter*{Resultados}\label{Resultados}
\addcontentsline{toc}{chapter}{Resultados} % si queremos que aparezca en el 
\markboth{}{} % encabezado

En este Cap\'itulo mostraremos los tiempos y memoria requerida de las diferentes implementaciones. La implementaci\'on b\'asica, la optimizada para CPU y la implementaci\'on con GPU solo en la funci\'on $interaccion$.
Para ello iremos modificando las variables del programa para generar problemas de tama\~no creciente. 

Cada funci\'on se le medir\'a el tiempo individualmente, la memoria se tomar\'a el total del programa.

No se medir\'a el tiempo que toma en resolver el problema de autovalores ni su memoria requerida, ya que la resuelve una biblioteca de terceros y depende mucho de que biblioteca o paquete que se use. Tambi\'en se puede exportar las matrices para ser luego resueltos con las herramientas que se desee. Las matrices exportadas van a estar en matrices comprimidas por columnas (CCS \ref{CCS}).

\section{Experimentos y An\'alisis}

\subsubsection{Medici\'on de rendimiento en el procesamiento}
Para las pruebas solo nos centraremos en la variable $L_{INT}$ ya que las demas variables no influyen en el tama\~no del problema, salvo $INT_G$ y $KORD$ que usualmente no son demasiado grandes.
Al comparar rendimiento, nos interesa el tiempo y la memoria que toma calcular el sistema a diagonalizar. 

En la tabla \ref{table:env} detallamos el entorno utilizado para realizar las pruebas. 



\begin{figure}[h]
\begin{center}
\label{table:env}
\small
\begin{tabular}{ |c|c| }
  \hline
  \multicolumn{2}{|c|}{\textbf{CPU}} \\
  \hline

  Procesador & Intel(R) Core(TM) i7 CPU 980 @ 3.33GHz \\
  \hline
  Memoria & 24 GB DDR3@  \\
  \hline
  Arquitectura & Nehalem \\
  \hline
  \multicolumn{2}{|c|}{\textbf{GPU}} \\
  \hline
  Procesador &GTX 980 \\
  \hline
  Memoria & 4 GB DDR5 \\
  \hline
  Interfaz & PCI Express 2.0 \\
  \hline
  Arquitectura & Maxwell \\
  \hline
  Procesador & K40 \\
  \hline
  Memoria & 12 GB DDR5 \\
  \hline
  Interfaz & PCI Express 2.0 \\
  \hline
  Arquitectura & Kepler \\
  \hline

\end{tabular}
\end{center}
\caption{Entorno}
\end{figure}

\subsubsection{Medici\'on en el uso de Memoria}
En el gr\'afico de la Figura \ref{graph:memoria} se puede ver como var\'ia la cantidad de memoria necesaria para el c
\'alculo del sistema en la versi\'on no optimizada, se corta en el experimento en un $L_{INT}=200$ pues en el 
experimento siguiente $L_{INT}=250$ supera la cantidad de memoria de la computadora utilizada por tanto su c\'omputo 
se demora enormemente.
Lo destacable del Gr\'afico \ref{graph:memoria} es como el crecimiento de ambas curvas es de ordenes diferentes, lo 
cual no guardar los ceros (o la m\'inima cantidad posible) ofrece una notable escalabilidad en cuanto a memoria.

\subsubsection{Medici\'on del tiempo de ejecuci\'on}
En el proceso del m\'etodo se puede separar en cuatro partes importantes.
\begin{enumerate}
    \item Calculo matrices
    \item Iteraccion
    \item Normalizaci\'on
    \item Sener
    \item Calculo de autovectores y autovalores.
\end{enumerate}

Podemos observar en el Gr\'afico \ref{graph:c_vs_fortran} que salvo en el caso de $calculo\-matrices$ el orden algor\'itmico es menor, esto es consecuencia de no computar los ceros que son de orden mayor a la cantidad de no-ceros y esto es la mayor ganancia, haber cambiado las estructuras de datos implico bajar uno o dos ordenes (depende de la funci\'on). En $calculo\-matrices$ se mantiene el orden pero se baja la pendiente dado por las dem\'as mejoras como factorizaci\'on y recalculo de valores simples.
La optimizaci\'on en GPU se realiz\'o en el m\'etodo $interaccion$ ya que se realiza una itegraci\'on y es directamente paralelizable, los resultados se pueden observar en el Gr\'afico \ref{graph:cpu_vs_gpu}.



\begin{figure}[!htbp]
  \begin{center}
    \leavevmode

    \includegraphics[scale=0.8]{memoria.eps}

    \caption{Mediciones del pico de memoria}
    \label{graph:memoria}
  \end{center}
\end{figure}

\begin{figure}[!htbp]
  \begin{center}
    \leavevmode

    \includegraphics[scale=0.5]{optimizado.eps}

    \caption{Mediciones de tiempo de las diferentes funciones}
    \label{graph:c_vs_fortran}
  \end{center}
\end{figure}

\begin{figure}[!htbp]
  \begin{center}
    \leavevmode
 
    \includegraphics[scale=0.8]{cpu_vs_gpu.eps}

    \caption{Comparaci\'on entre CPU y GPU}

    \label{graph:cpu_vs_gpu}
  \end{center}
\end{figure}
